{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models subpackage tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class is a generic class used to manage neural networks implemented with Keras. It offers methods to save, load, train and use for classification the neural networks.\n",
    "\n",
    "Melusine provides two built-in Keras model : cnn_model and rnn_model based on the models used in-house at Maif. However the user is free to implement neural networks tailored for its needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class can take as input either :\n",
    "- a text input : a cleaned text, usually the cleaned body or the concatenation of the cleaned body and the cleaned header.\n",
    "- a text input and a metadata input : the metadata input has to be dummified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_emails_preprocessed = pd.read_csv('./data/emails_preprocessed.csv', encoding='utf-8', sep=';')\n",
    "df_emails_preprocessed['clean_header'] = df_emails_preprocessed['clean_header'].astype(str)\n",
    "df_emails_preprocessed['clean_body'] = df_emails_preprocessed['clean_body'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['body', 'header', 'date', 'from', 'to', 'label', 'is_begin_by_transfer',\n",
       "       'is_answer', 'is_transfer', 'structured_historic', 'structured_body',\n",
       "       'last_body', 'clean_body', 'clean_header', 'tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails_preprocessed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new clean_text column is the concatenation of the clean_header column and the clean_body column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails_preprocessed['clean_text'] = df_emails_preprocessed['clean_header'] + \" \" + df_emails_preprocessed['clean_body']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'devis habitation je suis client chez vous pouvez vous m etablir un devis pour mon fils qui souhaite louer l appartement suivant : 25 rue du rueimaginaire flag_cp_ '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails_preprocessed.clean_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the metadata used are :\n",
    "- the extension : gmail, outlook, wanadoo..\n",
    "- the day of the week at which the email has been sent\n",
    "- the hour at which the email has been sent\n",
    "- the minute at which the email has been sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('./data/metadata.csv', encoding='utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['extension__0', 'extension__1', 'extension__2', 'extension__3',\n",
       "       'extension__4', 'extension__5', 'extension__6', 'extension__7',\n",
       "       'extension__8', 'dayofweek__0', 'dayofweek__1', 'dayofweek__3',\n",
       "       'dayofweek__4', 'hour__6', 'hour__8', 'hour__9', 'hour__10', 'hour__11',\n",
       "       'hour__12', 'hour__14', 'hour__15', 'hour__16', 'hour__17', 'hour__18',\n",
       "       'hour__20', 'hour__22', 'min__0', 'min__2', 'min__4', 'min__6',\n",
       "       'min__9', 'min__10', 'min__11', 'min__12', 'min__15', 'min__16',\n",
       "       'min__19', 'min__20', 'min__21', 'min__22', 'min__24', 'min__28',\n",
       "       'min__29', 'min__30', 'min__32', 'min__33', 'min__37', 'min__38',\n",
       "       'min__39', 'min__40', 'min__44', 'min__45', 'min__49', 'min__54',\n",
       "       'min__56', 'min__58'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extension__0</th>\n",
       "      <th>extension__1</th>\n",
       "      <th>extension__2</th>\n",
       "      <th>extension__3</th>\n",
       "      <th>extension__4</th>\n",
       "      <th>extension__5</th>\n",
       "      <th>extension__6</th>\n",
       "      <th>extension__7</th>\n",
       "      <th>extension__8</th>\n",
       "      <th>dayofweek__0</th>\n",
       "      <th>...</th>\n",
       "      <th>min__37</th>\n",
       "      <th>min__38</th>\n",
       "      <th>min__39</th>\n",
       "      <th>min__40</th>\n",
       "      <th>min__44</th>\n",
       "      <th>min__45</th>\n",
       "      <th>min__49</th>\n",
       "      <th>min__54</th>\n",
       "      <th>min__56</th>\n",
       "      <th>min__58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   extension__0  extension__1  extension__2  extension__3  extension__4  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             1             0             0             0             0   \n",
       "3             0             0             0             1             0   \n",
       "4             1             0             0             0             0   \n",
       "\n",
       "   extension__5  extension__6  extension__7  extension__8  dayofweek__0  ...  \\\n",
       "0             0             0             0             1             0  ...   \n",
       "1             0             0             0             1             0  ...   \n",
       "2             0             0             0             0             0  ...   \n",
       "3             0             0             0             0             0  ...   \n",
       "4             0             0             0             0             0  ...   \n",
       "\n",
       "   min__37  min__38  min__39  min__40  min__44  min__45  min__49  min__54  \\\n",
       "0        0        0        0        0        0        0        1        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        1        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   min__56  min__58  \n",
       "0        0        0  \n",
       "1        0        0  \n",
       "2        0        0  \n",
       "3        0        0  \n",
       "4        0        0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a Pandas dataframe with a clean_text column that will be used for the text input and columns containing the dummified metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df_emails_preprocessed['clean_text'],df_meta],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y is a numpy array containing the encoded labels :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = df_emails_preprocessed['label']\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10,  3,  0,  0,  4,  7, 10,  1, 10,  2,  5, 10, 10,  4,  7,  7,\n",
       "       10,  0,  9,  4, 10,  4,  7, 10, 10,  6,  7,  3,  8, 10, 10, 10,  4,\n",
       "        7,  3,  5,  4,  4, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NeuralModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from melusine.models.train import NeuralModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class is a generic class used to manage neural networks implemented with Keras. It offers methods to save, load, train and use for classification the neural networks.\n",
    "\n",
    "Its arguments are :\n",
    "- **architecture_function :** a function returning a Model instance from Keras.\n",
    "- **pretrained_embedding :** the pretrained embedding matrix as an numpy array.\n",
    "- **text_input_column :** the name of the column that will provide the text input, by default clean_text.\n",
    "- **meta_input_list :** the list of the names of the columns containing the metadata. If empty list or None the model is used without metadata. Default value, ['extension', 'dayofweek', 'hour', 'min'].\n",
    "- **vocab_size :** the size of vocabulary for neurol network model. Default value, 25000.\n",
    "- **seq_size :** the maximum size of input for neural model. Default value, 100.\n",
    "- **loss :** the loss function for training. Default value, 'categorical_crossentropy'.\n",
    "- **batch_size :** the size of batches for the training of the neural network model. Default value, 4096.\n",
    "- **n_epochs :** the number of epochs for the training of the neural network model. Default value, 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### architecture_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.models.neural_architectures import cnn_model, rnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**architecture_function** is a function returning a Model instance from Keras.\n",
    "Melusine provides two built-in neural networks : **cnn_model** and **rnn_model** based on the models used in-house at Maif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pretrained_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding have to be trained on the user's dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.nlp_tools.embedding import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "pretrained_embedding = Embedding().load('./data/embedding.pickle') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralModel used with text and metadata input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural network model will use the **clean_text** column for the text input and the dummified **extension**, **dayofweek**, **hour** and **min** as metadata input :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NeuralModel(architecture_function=cnn_model,\n",
    "                       pretrained_embedding=pretrained_embedding,\n",
    "                       text_input_column=\"clean_text\",\n",
    "                       meta_input_list=['extension', 'dayofweek', 'hour', 'min'],\n",
    "                       n_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 2.4016 - acc: 0.1000\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3813 - acc: 0.1000\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3189 - acc: 0.2000\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 2.1998 - acc: 0.3000\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.0979 - acc: 0.3500\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.1648 - acc: 0.3250\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.1211 - acc: 0.3250\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.9642 - acc: 0.2750\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 2.0871 - acc: 0.2250\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 2.0354 - acc: 0.3250\n"
     ]
    }
   ],
   "source": [
    "nn_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **save_nn_model** method saves :\n",
    "- the Keras model as a json file \n",
    "- the weights as a h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save_nn_model(\"./data/nn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the **save_nn_model** used the NeuralModel object can be saved as a pickle file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "_ = joblib.dump(nn_model,\"./data/nn_model.pickle\",compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel saved as a pickle file has to be loaded first : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = joblib.load(\"./data/nn_model.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the Keras model and its weights can be loaded :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.load_nn_model(\"./data/nn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = nn_model.predict(X)\n",
    "y_res = le.inverse_transform(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['habitation', 'vehicule', 'habitation', 'habitation', 'habitation',\n",
       "       'habitation', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'habitation', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'habitation', 'habitation', 'habitation', 'habitation',\n",
       "       'habitation', 'habitation', 'vehicule', 'habitation', 'habitation',\n",
       "       'habitation', 'vehicule', 'habitation', 'vehicule', 'habitation',\n",
       "       'habitation', 'vehicule', 'habitation', 'vehicule', 'habitation',\n",
       "       'habitation', 'habitation', 'habitation', 'habitation',\n",
       "       'habitation', 'vehicule'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralModel used with only text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_emails_preprocessed[['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NeuralModel(architecture_function=cnn_model,\n",
    "                       pretrained_embedding=pretrained_embedding,\n",
    "                       text_input_column=\"clean_text\",\n",
    "                       meta_input_list=None,\n",
    "                       n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/melusine/nlp_tools/tokenizer.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['tokens'] = apply_func(X, self.tokenize)\n",
      "/Users/florianarthur/opt/anaconda3/envs/emails/lib/python3.6/site-packages/melusine/nlp_tools/tokenizer.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['tokens'] = apply_func(X, lambda x: x['tokens'][0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 31ms/step - loss: 2.3975 - acc: 0.1000\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3861 - acc: 0.1250\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.3492 - acc: 0.2250\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.2867 - acc: 0.3000\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.2103 - acc: 0.3000\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 2.1693 - acc: 0.2750\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.0912 - acc: 0.3000\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.0938 - acc: 0.3000\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.1150 - acc: 0.2250\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.0421 - acc: 0.4000\n"
     ]
    }
   ],
   "source": [
    "nn_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res = nn_model.predict(X)\n",
    "y_res = le.inverse_transform(y_res)\n",
    "y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emails",
   "language": "python",
   "name": "emails"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
